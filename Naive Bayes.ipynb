{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes é um técnica simples de construção de classificadores. Não é um único algoritmo para treinamento de classificadores, mas uma família de algoritmos baseada num princípio em comum: todos os classificadores Naive Bayes assumem que o valor de um atributo em particular é *independente* do valor dos outros atributos, dada a variável da classe. Isso é o que torna o Naive Bayes *Naive*: ele não considera a dependência entre os atributos. Se pensarmos no caso de classificação textual - onde cada palavra representa um atributo -, por exemplo, a ordem das palavras são importantes para a classificação.\n",
    "\n",
    "**Vantagens**:\n",
    "- Requer um baixo número de dados de treinamento para estimar parâmetros do modelo\n",
    "- Facilmente escalável\n",
    "- Performance comparável com outros classificadores\n",
    "\n",
    "**Desvantagens**:\n",
    "- Pode ser superado por outros classificadores, como árvores de decisão e Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Probabilístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basicamente, o Naive Bayes é um **modelo de probabilidade condicional**: dado uma instância a ser classificada, representada por um vetor $x = (x_1,...,x_n)$ com *n* atributos (varáveis independentes), é calculada a probabilidade:\n",
    "\n",
    "$$p(C_k | x_1,...,x_n)$$\n",
    "\n",
    "Ou seja, a probabilidade dessa instância pertencer a cada uma das *k* classes C_k.\n",
    "\n",
    "Reformulando esse modelo, e aplicando o **Teorema de Bayes**, a probabilidade condicional pode ser escrita como:\n",
    "\n",
    "$$p(C_k|x) = \\frac{p(C_k)p(x|C_k)}{p(x)}$$\n",
    "\n",
    "Em texto plano, podemos escrever essa equação como segue:\n",
    "\n",
    "$$posteriori = \\frac{priori \\times likelihood}{evidence}$$\n",
    "\n",
    "Na prática, somente nos interessa o numerador dessa fração, já que o denominador não depende de $C$ e os valores dos atributos $F_i$ são dados, logo o denominador é constante. O númerador é equivalente ao modelo de probabilidade conjunta (*joint probability*):\n",
    "\n",
    "$$p(C_k,x_1,...,x_n)$$\n",
    "\n",
    "Que pode ser escrita, através da regra da cadeia por aplicações repetidas da definição de probabilidade condicional:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}p(C_{k},x_{1},\\dots ,x_{n})&=p(x_{1},\\dots ,x_{n},C_{k})\\\\&=p(x_{1}\\vert x_{2},\\dots ,x_{n},C_{k})p(x_{2},\\dots ,x_{n},C_{k})\\\\&=p(x_{1}\\vert x_{2},\\dots ,x_{n},C_{k})p(x_{2}\\vert x_{3},\\dots ,x_{n},C_{k})p(x_{3},\\dots ,x_{n},C_{k})\\\\&=\\dots \\\\&=p(x_{1}\\vert x_{2},\\dots ,x_{n},C_{k})p(x_{2}\\vert x_{3},\\dots ,x_{n},C_{k})\\dots p(x_{n-1}\\vert x_{n},C_{k})p(x_{n}\\vert C_{k})p(C_{k})\\\\\\end{aligned}\n",
    "$$\n",
    "\n",
    "Como o Naive Bayes assume que os atributos são independentes:\n",
    "\n",
    "$$p(x_i \\vert x_{i+1},\\dots,x_n,C_k)=p(x_i \\vert C_k)$$\n",
    "\n",
    "Portanto, o modelo de probabilidade conjunta pode ser expresso como:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}p(C_{k}\\vert x_{1},\\dots ,x_{n})&\\varpropto p(C_{k},x_{1},\\dots ,x_{n})\\\\&\\varpropto p(C_{k})\\ p(x_{1}\\vert C_{k})\\ p(x_{2}\\vert C_{k})\\ p(x_{3}\\vert C_{k})\\ \\cdots \\\\&\\varpropto p(C_{k})\\prod _{{i=1}}^{n}p(x_{i}\\vert C_{k})\\,.\\end{aligned}\n",
    "$$\n",
    "\n",
    "Pela suposição de independência, a distribuição condicional sobre a variável de classe $C$ é:\n",
    "\n",
    "$$p(C_{k}\\vert x_{1},\\dots ,x_{n})=p(C_{k})\\prod _{{i=1}}^{n}p(x_{i}\\vert C_{k})$$\n",
    "\n",
    "Logo, o classificador Bayesiano, é a função que atribui a classe $y = C_k$ para algum *k* da seguinte forma:\n",
    "\n",
    "$$y = \\operatorname{argmax}{p(C_k)\\prod _{{i=1}}^{n}p(x_{i}\\vert C_{k})}$$\n",
    "\n",
    "Em outras palavras, calculamos a probabilidade de uma instância pertencer a cada classe e atribuímos o label cuja classe tem a maior probabilidade de ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
